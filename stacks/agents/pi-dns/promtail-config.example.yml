# Promtail Configuration for Pi DNS Agent
# Ships Pi-hole and Unbound logs to Dell CoreSrv Loki (Integrated mode)
#
# This configuration is designed for the Single Pane of Glass (SPoG) architecture
# where the Dell CoreSrv hosts centralized observability (Loki, Grafana, Prometheus)
#
# OPTIONAL COMPONENT - Only needed for Integrated mode with CoreSrv
#
# Setup Instructions:
# Option 1 (Recommended): Use environment variables
#   1. Copy this file to promtail-config.yml (no edits needed)
#   2. Set LOKI_URL environment variable before deploying
#      export LOKI_URL=http://your-coresrv-ip:3100
#   3. Deploy using docker-compose.yml
#
# Option 2: Edit config file directly
#   1. Copy this file to promtail-config.yml
#   2. Replace ${LOKI_URL} below with your actual Loki URL
#   3. Deploy using docker-compose.yml
#
# Note: The environment variable LOKI_URL is set in docker-compose.yml
#       with a default value of http://192.168.8.100:3100

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  # Dell CoreSrv Loki endpoint
  # Uses LOKI_URL environment variable (set in docker-compose.yml or via export)
  # Default: http://192.168.8.100:3100
  - url: ${LOKI_URL}/loki/api/v1/push

    # Batching configuration for efficiency
    batchwait: 1s
    batchsize: 1048576  # 1MB

    # Retry configuration for network resilience
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10

    # Timeout
    timeout: 10s

    # Optional: Add authentication if Loki requires it
    # basic_auth:
    #   username: <username>
    #   password: <password>

scrape_configs:
  # Pi-hole Query Logs
  - job_name: pihole-queries
    static_configs:
      - targets:
          - localhost
        labels:
          job: pihole
          host: pi-dns
          stack: dns-ha
          component: dns-blocker
          __path__: /var/log/pihole/*.log

    pipeline_stages:
      # Parse Pi-hole query log format
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+)\s+(?P<query_type>\S+)\s+(?P<domain>\S+)\s+(?P<client>\S+)\s+(?P<action>\S+)'

      # Extract timestamp
      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      # Add labels for filtering
      - labels:
          query_type:
          action:

  # Pi-hole FTL Logs
  - job_name: pihole-ftl
    static_configs:
      - targets:
          - localhost
        labels:
          job: pihole-ftl
          host: pi-dns
          stack: dns-ha
          component: dns-blocker
          __path__: /var/log/pihole/FTL.log

    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+)\s+(?P<severity>\S+):\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      - labels:
          severity:

  # Unbound DNS Resolver Logs
  - job_name: unbound
    static_configs:
      - targets:
          - localhost
        labels:
          job: unbound
          host: pi-dns
          stack: dns-ha
          component: dns-resolver
          __path__: /var/log/unbound/*.log

    pipeline_stages:
      - regex:
          expression: '^\[(?P<timestamp>[^\]]+)\]\s+unbound\[(?P<pid>\d+)\]:\s+\[(?P<thread>\d+)\]\s+(?P<level>\S+):\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: RFC3339

      - labels:
          level:

  # Keepalived High Availability Logs
  - job_name: keepalived
    static_configs:
      - targets:
          - localhost
        labels:
          job: keepalived
          host: pi-dns
          stack: dns-ha
          component: ha-manager
          __path__: /var/log/syslog

    pipeline_stages:
      # Only match Keepalived entries
      - match:
          selector: '{job="keepalived"}'
          stages:
            - regex:
                expression: '.*Keepalived.*'
            - regex:
                expression: '^(?P<timestamp>\S+\s+\S+\s+\S+)\s+(?P<hostname>\S+)\s+Keepalived.*:\s+(?P<message>.*)'
            - timestamp:
                source: timestamp
                format: 'Jan _2 15:04:05'
            - labels:
                hostname:

  # Docker Container Logs (from DNS stack containers)
  - job_name: docker-containers
    static_configs:
      - targets:
          - localhost
        labels:
          job: docker
          host: pi-dns
          stack: dns-ha
          __path__: /var/lib/docker/containers/*/*.log

    pipeline_stages:
      # Parse Docker JSON log format
      - json:
          expressions:
            stream: stream
            log: log
            time: time

      - timestamp:
          source: time
          format: RFC3339Nano

      - output:
          source: log

      # Extract container ID from path
      - regex:
          expression: '^/var/lib/docker/containers/(?P<container_id>[^/]+)/.*'
          source: filename

      - labels:
          container_id:
          stream:

  # System Logs (for correlation and debugging)
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: system
          host: pi-dns
          stack: dns-ha
          component: os
          __path__: /var/log/syslog

    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+\s+\S+)\s+(?P<hostname>\S+)\s+(?P<service>\S+)(\[(?P<pid>\d+)\])?:\s+(?P<message>.*)'

      - timestamp:
          source: timestamp
          format: 'Jan _2 15:04:05'

      - labels:
          hostname:
          service:

      # Filter out noise
      - match:
          selector: '{job="system"}'
          action: drop
          drop_counter_reason: "noisy_service"
          stages:
            - regex:
                expression: '(CRON|systemd|dbus)'
                source: service

# Resource limits for Raspberry Pi
limits_config:
  readline_rate: 10000
  readline_burst: 20000
